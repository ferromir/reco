# RECO

Recommendations service that uses a graph model with in-memory data.

## Run

I strongly recommend running the application using docker:

```bash
docker compose build && docker compose up
```

## API Docs

An OpenAPI documentation is available at `http://localhost:8080/docs`

## Functionality

The endpoints provide the following functionality:
* Add an entity.
* Add a relationship.
* Search for entities based on a given criteria.
* Generate recommendations based on relationships.

## Example of search

The search endpoint can be tried with the data loaded at startup by running:

```bash
curl --location 'http://localhost:8080/entities/search' \
--header 'Content-Type: application/json' \
--data '{
    "generation": "genz"
}'
```

Of course, more fields can be added to the criteria.

## Example of add entity

```bash
curl --location 'http://localhost:8080/entities' \
--header 'Content-Type: application/json' \
--data '{
    "id": "fernando",
    "props": {
        "type": "person",
        "generation": "millennial"
    }
}'
```

## Example of add relationship

```bash
curl --location --request POST 'http://localhost:8080/entities/fernando/likes/coldplay'
```

## Example of recommendation generation

In order to try the generation, the following curl command can be executed:

```bash
curl --location 'http://localhost:8080/entities/fernando/recommend' \
--header 'Content-Type: application/json' \
--data '["likes", "is_liked_by", "likes"]'
```

The application loads the following relationships during startup:

```
fernando likes coldplay
keyla likes coldplay
keyla likes u2
noel likes u2
noel likes oasis
clara likes the1975
coldplay is liked by fernando
coldplay is liked by keyla
u2 is liked by keyla
u2 is liked by noel
oasis is liked by noel
the1975 is liked by clara
```

The goal here is that `fernando` can receive artist recommendations based on the likes of people with similar taste in music. So the process would look like:

* Find artists that fernando likes.
* Find people who like those artists.
* Find artists that those people like.

In order to achieve this we pass an array of links: `likes, is_liked_by, likes`.

If we follow the data we see that only keyla likes coldplay just like fernando, so the result recommendation is u2.

The algorithm does not have a depth limit so more links can be provided.

## Design decisions

* Selection of FastAPI.
* The search functionality uses only exact matches on properties, therefore range queries are not supported.
* The id of entities is provided by the api user and not generated by the backend for the sake of prototyping and easier testing.
* In order to provide a fast search of entities, hashing indexing has been used. This decision is directly linked to the decision of using only exact matches.
* Entities have properties, which allow us to fulfill the search requirement.
* Relationships do not have properties. Recommendation generation uses the "link" attribute of the relationship (e.g. "likes", "is_liked_by", etc...).
* DFS as algorithm for generating recommendations. This is a modified version using link filters to only traverse the desired relationships using also the depth of the search to identify the link needed.

## Out of scope

* Mutability.
* Concurrency control and thread safety.
* Fine grained validation (e.g. max length of strings, amount of properties, etc...).


## Scalability and Improvements

So far this has been a prototype, using an in-memory application. To develop in a production environment I would suggest:

* Separate the system into 3 microservices.
  * API - to ingest entities and relationships providing strong guarantees and consistency.
  * Search - optimized for search entities. This could be powered by Elasticsearch.
  * Recommendations - responsible for generating recommendations, powerered by a graph database.
* A CQRS architecture in which the API provides the write side. The data can be stored in document store or a relational database.
* A streaming solution to publish state changes from the write side of the system (such as Kafka, NATS, etc..).
* The search and graph storages would be projections optimized for their specific end-user needs. This will allow us to update, rebuild and develop quickly.
